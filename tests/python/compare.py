"""
:author: Alberto M. Esmoris Pena

Utils for point cloud operations, e.g., point cloud comparison.
"""

import laspy
import pandas as pd
import numpy as np

from pathlib import Path
from scipy.spatial import KDTree as KDT

# ---   CONSTANTS   --- #
# --------------------- #
# Expected names for the features
PCLOUD_FNAME_GPS_TIME = "gps_time"
PCLOUD_FNAME_REFLECTANCE = "reflectance"
PCLOUD_FNAME_NIR = "nir"


# ---   POINT CLOUD   --- #
# ----------------------- #
class PointCloud:
    """
    Class representing a point cloud.

    :ivar X: The structure space matrix, i.e., the matrix of point-wise
        coordinates.
    :vartype X: :class:`np.ndarray`
    :ivar fnames: The names for each feature.
    :vartype fnames: list of str
    :ivar F: The feature space matrix, i.e., the matrix of point-wise features.
    :vartype F: :class:`np.ndarray` or None
    :ivar y: The vector of classes (represented by integers), if any.
    :vartype: :class:`np.ndarray` or None
    """

    # ---   CONSTRUCTION   --- #
    # ------------------------ #
    def __init__(self, X, fnames=None, F=None, y=None):
        self.X = X
        self.F = F
        self.y = y
        self.fnames = fnames

    @staticmethod
    def from_las(las, fnames=None, include_classes=False):
        """
        Build a point cloud object from the given LAS.

        :param las: The LAS object as generated by laspy.
        :param fnames: The names of the features that must be considered.
        :param include_classes: Whether to consider the classification (True)
            or not (False).
        :return: Built point cloud from given LAS.
        :rtype: :class:`.PointCloud`
        """
        # Extract structure space
        scales, offsets = las.header.scales, las.header.offsets
        X = np.array(
            [
                las.X * scales[0] + offsets[0],
                las.Y * scales[1] + offsets[1],
                las.Z * scales[2] + offsets[2],
            ]
        ).T
        # Extract features
        F = None
        if fnames is not None:
            F = np.array([las[fname] for fname in fnames]).T
        # Extract classes
        y = None
        if include_classes:
            y = np.array(las.classification)
        # Build point cloud
        return PointCloud(X, fnames=fnames, F=F, y=y)

    @staticmethod
    def from_las_file(path):
        """
        Build a point cloud object from the LAS file at the given path.

        :param path: Path to the LAS file.
        """
        return PointCloud.from_las(laspy.read(path))

    @staticmethod
    def from_xyz_file(path, cols, names, sep=" "):
        """
        Build a point cloud object from the XYZ/CSV file at the given path.

        :param path: Path to the XYZ/CSV file.
        :type path: str
        :param cols: The indices of the columns to be selected.
        :type cols: list of int
        :param names: The name for each selected column. Note that "x", "y",
            "z" must be given as the coordinates are necessary to build the
            point cloud (features and classes are optional). The name
            "classification" is reserved to the classes. Any name that has not
            been mentioned before will be understood as a feature.
        :type names: list of str
        """
        # Read data
        P = pd.read_csv(path, usecols=cols, names=names, header=None, sep=sep)
        # Extract structure space
        X = np.array([P["x"], P["y"], P["z"]]).T
        # Extract classes
        y = P["classification"] if "classification" in names else None
        # Extract features
        fnames = [
            name for name in names if name not in ["x", "y", "z", "classification"]
        ]
        F = None
        if len(fnames) > 0:
            F = np.vstack([P[fname] for fname in fnames]).T
        else:
            fnames = None
        # Build point cloud
        return PointCloud(X, fnames=fnames, F=F, y=y)

    # ---   ASSERT   --- #
    # ------------------ #
    def assert_equals(self, pcloud, eps=1e-5, k=16):
        """
        Assert whether two point clouds are equal.

        :param pcloud: The point cloud to compare with.
        :param eps: The numeric tolerance threshold.
        :param k: How many nearest neighbors must be considered. A high enough
            value of k implies that points with the same (x, y, z) but acquired
            at different times (i.e., ti != tj) will be properly handled. If
            GPSTime.
        """
        # Check number of points
        assert self.X.shape[0] == pcloud.X.shape[0]
        # Check feature names (feature order must also be the same)
        check = int(self.fnames is None) + int(pcloud.fnames is None)
        assert check != 1  # One has fnames, other does not
        if check == 0:  # Both have fnames
            assert len(self.fnames) == len(pcloud.fnames)
            for i, fname in enumerate(self.fnames):
                assert fname == pcloud.fnames[i]
        # Get neighborhoods
        N = self.find_neighborhoods(pcloud, k)
        # Compare coordinates
        NX = pcloud.X[N]
        np.testing.assert_allclose(self.X, NX, atol=eps, rtol=0)
        # Compare features
        if self.F is not None:
            # Check number of features
            assert np.all(np.array(self.F.shape) == np.array(pcloud.F.shape))
            # Check numerical differences in the features
            NF = pcloud.F[N]
            np.testing.assert_allclose(self.F, NF, atol=eps, rtol=0)
        # Compare classes
        check = int(self.y is None) + int(pcloud.y is None)
        assert check != 1  # One has classes, other does not
        if check == 0:  # Both have classes
            Ny = pcloud.y[N]
            assert np.any(self.y == Ny)

    # ---   UTILS   --- #
    # ----------------- #
    def find_neighborhoods(self, pcloud, k):
        """
        Find the nearest neighbor for each points in the self point cloud wrt
        the points in the given input point cloud.
        """
        # Find GPS time, if available
        gps_time_idx = None
        if self.fnames is not None:
            for i, fname in enumerate(self.fnames):
                if fname == PCLOUD_FNAME_GPS_TIME:
                    gps_time_idx = i
                    break
        # Build KDTree
        kdt = KDT(pcloud.X)
        # If no GPS time, take closest neighbor
        if gps_time_idx is None:
            return kdt.query(self.X, 1)[1].tolist()
        # If GPS time, untie min distance neighbors with time
        else:
            t = self.F[:, gps_time_idx]
            pcloud_t = pcloud.F[:, gps_time_idx]
            D, N = kdt.query(self.X, k)
            # NOTE that == is used, abs diff wrt eps could also be used
            min_distance_mask = (D.T == np.min(D, axis=1)).T
            N = [ni[min_distance_mask[i]] for i, ni in enumerate(N)]
            for i, ni in enumerate(N):
                jmin = np.argmin(np.abs(pcloud_t[ni] - t[i]))
                N[i] = ni[jmin]
            return N

    def shuffle(self):
        """
        Randomly shuffle the point cloud, i.e., random permutations on the
        points.
        """
        # Random shuffle on the structure space
        indices = np.arange(0, self.X.shape[0])
        np.random.shuffle(indices)
        self.X = self.X[indices]
        # Random shuffle any other array-like member attribute
        for attr in ["F", "y"]:
            if getattr(self, attr, None) is not None:
                setattr(self, attr, getattr(self, attr)[indices])
        return self  # Return the object itself, because fluent :)


def compare_clouds(cloud1_path: Path, cloud2_path: Path):
    cloud1 = PointCloud.from_las_file(cloud1_path)
    cloud2 = PointCloud.from_las_file(cloud2_path)
    cloud1.assert_equals(cloud2)


def speed_from_traj(trajectory_file):
    def mode(arr):
        vals, counts = np.unique(arr, return_counts=True)
        mode_idx = np.argwhere(counts == np.max(counts))
        mode_val = vals[mode_idx].flatten().tolist()[0]

        # round to 4 decimal places
        return np.round(mode_val, 3)

    # load trajectory file
    traj_data = np.loadtxt(trajectory_file, delimiter=" ", usecols=(0, 1, 2, 3))

    # get distance between all points
    points = traj_data[:, :2]
    d = np.diff(points, axis=0)
    segdists = np.sqrt((d**2).sum(axis=1))
    # get most frequent distance (ignore smaller distances from speedup/slowdown)
    dist = mode(segdists)

    # get time diff. between points (should always be the same, but we're nevertheless computing the mode to be safe)
    times = traj_data[:, 3]
    dt = np.diff(times, axis=0)
    time_diff = mode(dt)

    speed = dist / time_diff

    return speed
